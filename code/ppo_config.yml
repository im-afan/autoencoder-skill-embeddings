
# Tuned
HalfCheetahBulletEnv-v0: &pybullet-defaults
  normalize: true
  n_envs: 16
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  batch_size: 128
  n_steps: 512
  gamma: 0.99
  gae_lambda: 0.9
  n_epochs: 20
  ent_coef: 0.0
  sde_sample_freq: 4
  max_grad_norm: 0.5
  vf_coef: 0.5
  learning_rate: !!float 3e-5
  use_sde: True
  clip_range: 0.4
  policy_kwargs: "dict(log_std_init=-2,
                       ortho_init=False,
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"


#Tuned THIS IS CUSTOM 
AntTargetPosLowLevel-v0:
  <<: *pybullet-defaults
  learning_rate: !!float 3e-5
  policy_kwargs: "dict(log_std_init=-1,
                       ortho_init=False,
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"

#Tuned THIS IS CUSTOM 
AntTargetPosHighLevel-v0:
  <<: *pybullet-defaults
  learning_rate: !!float 3e-5
  policy_kwargs: "dict(log_std_init=-1,
                       ortho_init=False,
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"

#Tuned THIS IS CUSTOM 
AntObstacleLowLevel-v0:
  <<: *pybullet-defaults
  learning_rate: !!float 3e-5
  policy_kwargs: "dict(log_std_init=-1,
                       ortho_init=False,
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"
#Tuned THIS IS CUSTOM 
AntObstacleHighLevel-v0:
  <<: *pybullet-defaults
  learning_rate: !!float 3e-5
  policy_kwargs: "dict(log_std_init=-1,
                       ortho_init=False,
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"
#Tuned THIS IS CUSTOM 
AntTargetPosVelocityHighLevel-v0:
  <<: *pybullet-defaults
  learning_rate: !!float 3e-5
  policy_kwargs: "dict(log_std_init=-1,
                       ortho_init=False,
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"

#Tuned THIS IS CUSTOM 
PickAndPlaceLowLevel-v0:
  <<: *pybullet-defaults
  policy: "MultiInputPolicy"
  learning_rate: !!float 3e-5
  policy_kwargs: "dict(log_std_init=-1,
                       ortho_init=False,
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"

#Tuned THIS IS CUSTOM 
PickAndPlaceHighLevel-v0:
  <<: *pybullet-defaults
  policy: "MultiInputPolicy"
  learning_rate: !!float 3e-5
  policy_kwargs: "dict(log_std_init=-1,
                       ortho_init=False,
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"




#Tuned THIS IS CUSTOM 
PandaPickAndPlace-v3:
  <<: *pybullet-defaults
  policy: "MultiInputPolicy"
  learning_rate: !!float 3e-5
  policy_kwargs: "dict(log_std_init=-1,
                       ortho_init=False,
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"

#Tuned THIS IS CUSTOM 
ReachWithGripperLowLevel-v0:
  <<: *pybullet-defaults
  policy: "MultiInputPolicy"
  learning_rate: !!float 3e-5
  policy_kwargs: "dict(log_std_init=-1,
                       ortho_init=False,
                       activation_fn=nn.ReLU,
                       net_arch=dict(pi=[256, 256], vf=[256, 256])
                       )"